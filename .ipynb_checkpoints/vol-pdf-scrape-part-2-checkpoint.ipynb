{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping LADOT Volume Data from PDFs, Part 2\n",
    "\n",
    "##### Where I Left Off\n",
    "In the first python notebook, I described the process by which I was able to extract volume data from PDFs. At this point, the resulting data has been converted to .csv files, formatted for data analysis. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed: The specified module could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-191201d510c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mfolium\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplugins\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMarkerCluster\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgeopandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\geopandas\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeodataframe\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGeoDataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfile\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mread_file\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mread_postgis\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msjoin\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\geopandas\\io\\file.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mfiona\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\fiona\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msix\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mfiona\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCollection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBytesCollection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvsi_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mfiona\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drivers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdriver_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGDALEnv\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mfiona\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrvsupport\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msupported_drivers\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\fiona\\collection.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mfiona\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mfiona\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mogrext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mIterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mItemsIterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKeysIterator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mfiona\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mogrext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWritingSession\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m from fiona.ogrext import (\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed: The specified module could not be found."
     ]
    }
   ],
   "source": [
    "### Setup\n",
    "import csv\n",
    "import glob\n",
    "from datetime import datetime, date, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "import os\n",
    "import geopandas as gp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to start by loading and cleaning the tables provided by BOE. First there is the files table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load traffic data files table\n",
    "traffic_data_files_path = 'boe_tables/dbo_dot_traffic_data_files.csv'\n",
    "dbo_dot_traffic_data_files = pd.read_csv(traffic_data_files_path,\n",
    "                                         parse_dates=['UploadDT'],\n",
    "                                         encoding=\"ISO-8859-1\")\n",
    "\n",
    "# Drop rows where TrafficID is NaN, convert TrafficID to int type\n",
    "dbo_dot_traffic_data_files = dbo_dot_traffic_data_files.dropna(axis=0, how='any', subset=['TrafficID'])\n",
    "dbo_dot_traffic_data_files['TrafficID'] = dbo_dot_traffic_data_files['TrafficID'].astype(int)\n",
    "\n",
    "# Subset out Survey Data and Automatic Counts\n",
    "dbo_dot_traffic_data_files = dbo_dot_traffic_data_files[(dbo_dot_traffic_data_files['TrafficType'] == 'manual_count')]\n",
    "\n",
    "# See traffic data files head\n",
    "print(\"There are \" + str(len(dbo_dot_traffic_data_files)) + \" records in the table.\")\n",
    "#dbo_dot_traffic_data_files.head()\n",
    "dbo_dot_traffic_data_files[(dbo_dot_traffic_data_files['TrafficID'] == 1435)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load traffic data table\n",
    "traffic_data_path = 'boe_tables/dot_traffic_data.csv'\n",
    "dot_traffic_data = pd.read_csv(traffic_data_path)\n",
    "\n",
    "# Drop \"ext\" and \"Shape\" columns\n",
    "dot_traffic_data = dot_traffic_data.drop(['ext','Shape'], axis=1)\n",
    "#dot_traffic_data['IntersectionID'] = dot_traffic_data['IntersectionID'].astype(int)\n",
    "\n",
    "# See traffic data head\n",
    "dot_traffic_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combine both of the traffic data files\n",
    "file_table = dbo_dot_traffic_data_files.merge(dot_traffic_data,\n",
    "                                              how='left',\n",
    "                                              left_on='TrafficID',\n",
    "                                              right_on='TrafficID')\n",
    "file_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import output data tables\n",
    "manualcount_df = pd.read_csv('TrafficCountData/Results/manualcount.csv')\n",
    "pedestrian_df = pd.read_csv('TrafficCountData/Results/pedestrian.csv')\n",
    "peakvol_df = pd.read_csv('TrafficCountData/Results/peakvol.csv')\n",
    "specveh_df = pd.read_csv('TrafficCountData/Results/SpecialVehicle.csv')\n",
    "info_df = pd.read_csv('TrafficCountData/Results/info.csv')\n",
    "\n",
    "info_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Left join the traffic data table to the count info table\n",
    "info_df_merge = info_df.merge(file_table, how='left', left_on = 'count_id', right_on = 'ID')\n",
    "\n",
    "# Take a look at the length and head of the new table\n",
    "print(len(info_df_merge))\n",
    "info_df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import BOE Intersection spatial data\n",
    "boe_int = gp.GeoDataFrame.from_file('shp/Intersections.shp')\n",
    "# Take a peek at the table contents\n",
    "boe_int.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Join BOE table to info table\n",
    "info_df_merge = info_df_merge.merge(boe_int,\n",
    "                                    how='left',\n",
    "                                    left_on = 'IntersectionID',\n",
    "                                    right_on = 'CL_NODE_ID')\n",
    "\n",
    "print(len(info_df_merge))\n",
    "info_df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create new LA Basemap specifying map center, zoom level, and using Stamen Toner Tiles\n",
    "count_map = folium.Map([34.109279, -118.266087],\n",
    "                       tiles='Stamen Toner',\n",
    "                       zoom_start=11)\n",
    "\n",
    "# Subset out points with a NaN Coodinate values\n",
    "info_df_merge = info_df_merge[pd.notnull(info_df_merge['LAT'])]\n",
    "info_df_merge = info_df_merge[pd.notnull(info_df_merge['LON'])]\n",
    "\n",
    "#marker_cluster = MarkerCluster().add_to(count_map)\n",
    "\n",
    "locationlist = info_df_merge[['LAT','LON']].values.tolist()\n",
    "labels = info_df_merge[\"DocName\"].values.tolist()\n",
    "\n",
    "print(len(labels))\n",
    "print(len(locationlist))\n",
    "\n",
    "# Loop through the midblock_points df, add each point and value for 'intersection' column to the map\n",
    "#for point in range(len(locationlist)):\n",
    "    #popup = folium.Popup(labels[point], parse_html=True)\n",
    "    #folium.Marker(locationlist[point]\n",
    "                  #,popup='test'\n",
    "                 # \n",
    "                 #).add_to(count_map)\n",
    "    #popup = folium.Popup(str(row['intersection']), parse_html=True)\n",
    "    #popup issues. See here: https://github.com/python-visualization/folium/issues/726\n",
    "    #folium.Marker([row['lat'], row['lon']]).add_to(marker_cluster)\n",
    "for point in range(400):\n",
    "    popup = folium.Popup(labels[point], parse_html=True)\n",
    "    #popup = folium.Popup('hello')\n",
    "    folium.Marker(locationlist[point], popup = popup).add_to(count_map)\n",
    "# Show the map\n",
    "count_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import folium\n",
    "print(folium.__file__)\n",
    "print(folium.__version__)\n",
    "\n",
    "from folium.plugins import MarkerCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#map2 = folium.Map(location=[38.9, -77.05], tiles='CartoDB dark_matter', zoom_start=11)\n",
    "\n",
    "#marker_cluster = MarkerCluster().add_to(map2)\n",
    "\n",
    "#for point in range(0, len(locationlist)):\n",
    "#    folium.Marker(locationlist[point], popup=df_counters['Name'][point]).add_to(marker_cluster)\n",
    "#map2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = '{\"id\":{\"0\":411083201,\"1\":418513660,\"2\":528057543,\"3\":586713622,\"4\":647656728,\"5\":647656785,\"6\":1493456455,\"7\":1493456487,\"8\":2005894602,\"9\":2095344770,\"10\":2187987262,\"11\":2411692096,\"12\":2411698457,\"13\":2474058013,\"14\":2474058022,\"15\":2881830804,\"16\":2895323815,\"17\":2895323816,\"18\":2983919102,\"19\":3321734312,\"20\":3641568148,\"21\":4010355532,\"22\":4030622426,\"23\":4037746568,\"24\":4055719117,\"25\":4259001279,\"26\":4340535594,\"27\":4625994189,\"28\":4666687025},\"Latitude\":{\"0\":37.7673162,\"1\":37.7645003,\"2\":37.7682118,\"3\":37.7648492,\"4\":37.771672,\"5\":37.7721693,\"6\":37.7763591,\"7\":37.777046,\"8\":37.7690716,\"9\":37.766319,\"10\":37.7664253,\"11\":37.7770377,\"12\":37.7763106,\"13\":37.7739857,\"14\":37.774748,\"15\":37.775488,\"16\":37.7752166,\"17\":37.7759142,\"18\":37.7744588,\"19\":37.7760172,\"20\":37.7762395,\"21\":37.765011,\"22\":37.769195,\"23\":37.7750452,\"24\":37.7726713,\"25\":37.7717782,\"26\":37.7745253,\"27\":37.7768943,\"28\":37.7752822},\"Longitude\":{\"0\":-122.4219479,\"1\":-122.4216812,\"2\":-122.4223857,\"3\":-122.4320119,\"4\":-122.4331366,\"5\":-122.4307254,\"6\":-122.4180877,\"7\":-122.4172737,\"8\":-122.4277243,\"9\":-122.417422,\"10\":-122.4290387,\"11\":-122.4175698,\"12\":-122.4232558,\"13\":-122.424226,\"14\":-122.4226877,\"15\":-122.4159,\"16\":-122.4195185,\"17\":-122.4191912,\"18\":-122.4205881,\"19\":-122.4314951,\"20\":-122.4168763,\"21\":-122.4226685,\"22\":-122.4315398,\"23\":-122.4210561,\"24\":-122.4220741,\"25\":-122.4167145,\"26\":-122.4306476,\"27\":-122.4245402,\"28\":-122.4161381},\"Cafe Name\":{\"0\":\"Four Barrel Coffee\",\"1\":\"Muddy Waters\",\"2\":\"Carlin\\'s Cafe\",\"3\":\"Peet\\'s Coffee & Tea\",\"4\":\"Nectar\",\"5\":\"Cafe International\",\"6\":\"Ma\\'velous\",\"7\":\"Starbucks\",\"8\":\"Starbucks\",\"9\":\"Flying Pig Bistro\",\"10\":\"Church Street Cafe\",\"11\":\"Anderson Bakery\",\"12\":\"Blue Bottle Coffee\",\"13\":\"mercury cafe\",\"14\":\"gourmet and more\",\"15\":\"Cumaica\",\"16\":\"All Star Cafe\",\"17\":\"Boston Cafe\",\"18\":\"Javalencia Cafe\",\"19\":\"Alamo Square Cafe\",\"20\":\"Blue Bottle Coffee\",\"21\":\"Stanza\",\"22\":\"Duboce Park Cafe\",\"23\":\"Eden Cafe\",\"24\":\"Delessio Market & Bakery\",\"25\":\"Gaslamp Cafe\",\"26\":\"The Center SF Tea House\",\"27\":\"Cafe la Vie\",\"28\":\"Peet\\'s Coffee\"},\"Street\":{\"0\":\"Valencia Street\",\"1\":\"Valencia Street\",\"2\":\"Valencia Street\",\"3\":\"Market Street\",\"4\":\"Haight Street\",\"5\":\"Haight Street\",\"6\":\"Market Street\",\"7\":\"Market Street\",\"8\":\"Market Street\",\"9\":\"South Van Ness Avenue\",\"10\":null,\"11\":null,\"12\":null,\"13\":\"Octavia Street\",\"14\":null,\"15\":\"Mission Street\",\"16\":\"Market Street\",\"17\":\"Van Ness Avenue\",\"18\":\"Market Street\",\"19\":null,\"20\":\"Market Street\",\"21\":null,\"22\":\"Sanchez Street\",\"23\":\"Franklin Street\",\"24\":\"Market Street\",\"25\":\"Howard Street\",\"26\":\"Fillmore Street\",\"27\":\"Octavia Street\",\"28\":null}}'\n",
    "\n",
    "df = pd.read_json(data)\n",
    "\n",
    "location = df['Latitude'].mean(), df['Longitude'].mean()\n",
    "\n",
    "import folium\n",
    "\n",
    "#locationlist = df[[\"Latitude\",\"Longitude\"]].values.tolist()\n",
    "#labels = df[\"Cafe Name\"].values.tolist()\n",
    "\n",
    "locationlist = info_df_merge[['LAT','LON']].values.tolist()\n",
    "labels = info_df_merge[\"DocName\"].values.tolist()\n",
    "\n",
    "m = folium.Map(location=location, zoom_start=14)\n",
    "for point in range(20):\n",
    "    popup = folium.Popup(labels[point], parse_html=True)\n",
    "    #popup = folium.Popup('hello')\n",
    "    folium.Marker(locationlist[point], popup=popup).add_to(m)\n",
    "\n",
    "m\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
