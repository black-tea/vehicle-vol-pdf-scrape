{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping LADOT Volume Data from PDFs\n",
    "\n",
    "## Background\n",
    "At LADOT, we have a lot of historical (and relatively current) data on vehicle volume counts made at intersections throughout the city at various times. The problem is that the format the data are currently in - PDF - doesn't readily allow for the type of big data analyses that we would like to perform. So for this task I went about trying to develop a method for scraping these historical PDF counts and formatting them into usable data tables using any python package I could. I ended up settling on the pdfquery package, which is really just a lightweight wrapper around the much more well-known package PDFMiner.\n",
    "\n",
    "The roughly 1,000 PDFs typically (though not always) look like this (converted to images for display here):\n",
    "\n",
    "![Example Volume PDF](images/example.jpg?raw=TRUE)\n",
    "\n",
    "##### Format Advantages\n",
    "* One big advantage is that the (manual count) volume data sheets are generally in the same format.\n",
    "* With very few exceptions, the PDFs were generated from another program (rather than being scanned images).\n",
    "\n",
    "##### Format Challenges\n",
    "There are a few minor challenges:\n",
    "* There are multiple tables on each page, and each is formatted differently.\n",
    "* The tables / text do not always appear in the exact same location on each page, which meant I needed a range of parameters to test for the bounding boxes.\n",
    "\n",
    "## General Approach\n",
    "My approach can be broken down into the few key parts: (1) define bounding boxes, (2) search for text within the bounding boxes (3) reformat the resulting text into multiple data tables, and (4) join the resulting tables to the ID established by the Bureau of Engineering. The details of the PDF extraction process is covered in the next python notebook.\n",
    "\n",
    "##### Join Tables to BOE Count IDs\n",
    "The last step involves taking all the data generated by this process and relating it to both a GPS coordinate and the intersection ID of the BOE centerline.\n",
    "\n",
    "To do this exercise, I requested data from BOE that powers NavigateLA. There are actually two relevant tables that were provided by BOE. The first table, *dbo_dot_traffic_data_files* relates the name of the PDF to a TrafficID, so I can use this table to match the PDF names and get the resulting Traffic IDs. The second table, *dot_traffic_data* takes the TrafficID and relates it to the intersection ID (the same one that is usually on the front page of each traffic count summary) as well as the the lat / lon of the location and the intersection name. The structure of the two tables are shown below:\n",
    "\n",
    "*dbo_dot_traffic_data_files*\n",
    "* ID: Unique Identifier for the count\n",
    "* TrafficID: This seems to be an identifier for the location\n",
    "* TrafficType: Manual Count (manual_count) / Automatic Count (automatic_count) / Survey Data (survey_data)\n",
    "* DocName: Name of the PDF document\n",
    "* UniqueDocName: Not exactly sure the purpose of this one, perhaps at one time the DocNames were not unique?\n",
    "* UploadDT: Date the PDF was uploaded to NavLA\n",
    "\n",
    "*dot_traffic_data*\n",
    "* TrafficID: Identifier for the location\n",
    "* Intersection: The ID for the intersection, corresponding to the CL_NODE_ID in the BOE Centerline file\n",
    "* ext: ?\n",
    "* lat: Latitude\n",
    "* lon: Longitude\n",
    "* intersection: Intersection Name (eg ISLAND AVE at L ST)\n",
    "* Shape: geometry object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Setup\n",
    "import csv\n",
    "import glob\n",
    "from datetime import datetime, date, time\n",
    "import pdfquery\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import folium\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Getting Started\n",
    "I'm actually going to start by loading and cleaning the tables provided by BOE (mentioned just above). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-60b553303f19>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Load traffic data files table\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtraffic_data_files_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'boe_tables/dbo_dot_traffic_data_files.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdbo_dot_traffic_data_files\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraffic_data_files_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'UploadDT'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ISO-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Drop rows where TrafficID is NaN, convert TrafficID to int type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Load traffic data files table\n",
    "traffic_data_files_path = 'boe_tables/dbo_dot_traffic_data_files.csv'\n",
    "dbo_dot_traffic_data_files = pd.read_csv(traffic_data_files_path, parse_dates=['UploadDT'], encoding=\"ISO-8859-1\")\n",
    "\n",
    "# Drop rows where TrafficID is NaN, convert TrafficID to int type\n",
    "dbo_dot_traffic_data_files = dbo_dot_traffic_data_files.dropna(axis=0, how='any',subset=['TrafficID'])\n",
    "dbo_dot_traffic_data_files['TrafficID'] = dbo_dot_traffic_data_files['TrafficID'].astype(int)\n",
    "\n",
    "# Subset out Survey Data and Automatic Counts\n",
    "dbo_dot_traffic_data_files = dbo_dot_traffic_data_files[(dbo_dot_traffic_data_files['TrafficType'] == 'manual_count')]\n",
    "\n",
    "# See traffic data files head\n",
    "print(\"There are \" + str(len(dbo_dot_traffic_data_files)) + \" records in the table.\")\n",
    "dbo_dot_traffic_data_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I went ahead ane excluded any rows where the TrafficID was NaN (there was one value) since we would not be able to associate that to a valid intersection or location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TrafficID</th>\n",
       "      <th>IntersectionID</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>intersection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1912</th>\n",
       "      <td>3798</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.11</td>\n",
       "      <td>-118.25</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1917</th>\n",
       "      <td>3803</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.78</td>\n",
       "      <td>-118.25</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3129</th>\n",
       "      <td>3097</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.76</td>\n",
       "      <td>-118.29</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3131</th>\n",
       "      <td>3099</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.17</td>\n",
       "      <td>-118.40</td>\n",
       "      <td>WHITSETT AV AT OXNARD ST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3143</th>\n",
       "      <td>3111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.00</td>\n",
       "      <td>-118.28</td>\n",
       "      <td>Mid Block Ped Count Zone 3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TrafficID  IntersectionID    lat     lon                intersection\n",
       "1912       3798             NaN  34.11 -118.25                            \n",
       "1917       3803             NaN  33.78 -118.25                            \n",
       "3129       3097             NaN  33.76 -118.29                            \n",
       "3131       3099             NaN  34.17 -118.40    WHITSETT AV AT OXNARD ST\n",
       "3143       3111             NaN  34.00 -118.28  Mid Block Ped Count Zone 3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load traffic data table\n",
    "traffic_data_path = 'boe_tables/dot_traffic_data.csv'\n",
    "dot_traffic_data = pd.read_csv(traffic_data_path)\n",
    "\n",
    "# Drop \"ext\" and \"Shape\" columns\n",
    "dot_traffic_data = dot_traffic_data.drop(['ext','Shape'], axis=1)\n",
    "\n",
    "# See traffic data head\n",
    "dot_traffic_data[pd.isnull(dot_traffic_data['IntersectionID'])].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, looking at *dot_traffic_data* table, I first excluded the 'ext' and 'Shape' columns. Of note, there are a number of counts that have a NaN value for the IntersectionID. Some of these may have incorrectly been assigned to an intersection, but (as shown with the \"intersection' value of TrafficID 3111) many are midblock counts that won't have a valid intersection ID at all. Since these rows have valid lat / lon values, we can confirm this on a map using the Python Folium package.\n",
    "\n",
    "Even though these aren't at an intersection, most of them still have some sort of description value in the 'intersection' field. Along with plotting the locations using the lat / lon, I've added the labels to the points (click the point to see the label). After taking a look, I can confirm that many points are midblock locations. However, there are others that look like they are intersections, but perhaps just not locations on the BOE centerline. For example, there are three different locations that have to do with counts at Forest Lawn Dr and some other driveway. It is likely that these intersections don't exist in the valid BOE centerline file, which is why they don't contain a valid IntersectionID.\n",
    "\n",
    "Also of note - it looks like the points aren't plotted at exactly the right position. This is likely due to the fact that the lat / lon coords provided in the BOE table only go to two decimal places. I'm guessing that somehow the rest of values are getting cut off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'folium' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f4af07adf727>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Create new LA Basemap specifying map center, zoom level, and using Stamen Toner Tiles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m midblock_map = folium.Map([34.109279, -118.266087],\n\u001b[0m\u001b[0;32m      3\u001b[0m                           \u001b[0mtiles\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Stamen Toner'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                           zoom_start=11)\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'folium' is not defined"
     ]
    }
   ],
   "source": [
    "# Create new LA Basemap specifying map center, zoom level, and using Stamen Toner Tiles\n",
    "midblock_map = folium.Map([34.109279, -118.266087],\n",
    "                          tiles='Stamen Toner',\n",
    "                          zoom_start=11)\n",
    "\n",
    "# Subset out points with a NaN Intersection ID \n",
    "midblock_points = dot_traffic_data[pd.isnull(dot_traffic_data['IntersectionID'])]\n",
    "\n",
    "# Loop through the midblock_points df, add each point and value for 'intersection' column to the map\n",
    "for index, row in midblock_points.iterrows():\n",
    "    folium.Marker([row['lat'], row['lon']], popup=str(row['intersection'])).add_to(midblock_map)\n",
    "\n",
    "# Show the map\n",
    "midblock_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1: Make sure I have all the Volume Data PDFs (prep) and Related TraffcIDs\n",
    "I knew we needed to be able to join all of the data we pull out of the PDF to the table provided by BOE. Since the BOE Table *dbo_dot_traffic_data_files* contains a field with the filename, this is an easy join with our filename. Once this join is complete we will have the TrafficID.\n",
    "\n",
    "My initial process for doing this involved just looping through *dbo_dot_traffic_data_files* (after subsetting for the manual counts as I did above), and then just grabbing a file with the same filename in my folder, but then I realized that there were many rows that did not have a PDF in the folder. By doing the join, I could easily identify which PDFs were missing.\n",
    "\n",
    "I went a bit further - to get a graphical sense of the differences, I went ahead and created a venn diagram showing the results of the join from the BOE table and my folder of manual PDF counts. As you can tell, there is quite a difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASEAAADuCAYAAAB21LHOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5K4ERQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc2ecf98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get Venn Diagram package\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib_venn import venn2, venn2_circles\n",
    "\n",
    "# Grab all PDFs within the folder\n",
    "files = glob.glob('TrafficCountData\\Manual\\Original\\*.pdf')\n",
    "file_names = [os.path.basename(file) for file in files]\n",
    "\n",
    "# Create df from filenames / paths\n",
    "pdf_df = pd.DataFrame(\n",
    "    {'path':files,\n",
    "     'filename':file_names\n",
    "    })\n",
    "\n",
    "# Join pdf_df to BOE tables\n",
    "traffic_data_files_leftjoin = dbo_dot_traffic_data_files.merge(pdf_df, how='left', left_on='DocName', right_on='filename')\n",
    "traffic_data_files_innerjoin = dbo_dot_traffic_data_files.merge(pdf_df, how='inner', left_on='DocName', right_on='filename')\n",
    "traffic_data_files_rightjoin = dbo_dot_traffic_data_files.merge(pdf_df, how='right', left_on='DocName', right_on='filename')\n",
    "\n",
    "### Create Venn Diagram showing differences\n",
    "\n",
    "# Subset sizes\n",
    "s = (\n",
    "    (len(traffic_data_files_leftjoin) - len(traffic_data_files_innerjoin)),  # BOE Table only count\n",
    "    (len(traffic_data_files_rightjoin)-len(traffic_data_files_innerjoin)),  # PDF Folder only count\n",
    "    len(traffic_data_files_innerjoin),  # Joined Files count\n",
    ")\n",
    "\n",
    "# Subset labels\n",
    "v = venn2(subsets=s, set_labels=('BOE Table Files', 'PDF Folder Files'))\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the Venn Diagram makes obvious, there is quite a difference. Of the 1,018 PDF files I started with, I was able to match 955 (~94%) of them to a row in the BOE table. Roughly 6% of the files (63) were unable to be matched in the BOE table.\n",
    "\n",
    "However, it looks like the folder of Manual PDF counts that I was initially pulling from contained only about 10% (1018 of the 9034 total) of the manual count files in BOE's NavigateLA system. We don't have to give up here. Since NavigateLA hosts the PDFs online (and they are public), we can go ahead and download them from the NavigateLA website to fill out our set of Manual Count PDFs. We will do this by (1) looping through all the names in the BOE table that do not have a match and (2) using the python urllib library to pull the PDFs to a new folder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2: Download the PDF documents (prep)\n",
    "This script loops through my table of document names and downloads the PDFs from the web. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "import time\n",
    "from pathlib2 import Path\n",
    "\n",
    "# Location to where I will be downloading the files\n",
    "folder = \"data/TrafficCountData/Manual/All/\"\n",
    "\n",
    "# Base URL \n",
    "base_url = \"http://boemaps.eng.ci.la.ca.us/dot/traffic_data/manual_counts/\"\n",
    "\n",
    "# Get the filenames from the BOE table that don't yet have a matching PDF\n",
    "traffic_data_files_missing = traffic_data_files_leftjoin[(~traffic_data_files_leftjoin.DocName.isin(traffic_data_files_innerjoin.DocName))&(~traffic_data_files_leftjoin.filename.isin(traffic_data_files_innerjoin.filename))]\n",
    "\n",
    "# Loop through resulting rows\n",
    "for index, row in traffic_data_files_missing.iterrows():\n",
    "    \n",
    "    # Filename, URL, Location\n",
    "    filename = row['DocName']\n",
    "    url = base_url + filename\n",
    "    download_location = folder + filename\n",
    "    \n",
    "    # If it is already in the folder from first round of NavLA downloads, skip\n",
    "    if Path(download_location).is_file():\n",
    "        pass\n",
    "    \n",
    "    # Otherwise, try to download\n",
    "    else:\n",
    "        \n",
    "        try:\n",
    "            # Download to folder\n",
    "            urllib.urlretrieve(url, download_location)\n",
    "\n",
    "            # To Not overwhelm the server\n",
    "            time.sleep(.2)\n",
    "        \n",
    "        except:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [Update 1/7/18] Step 3: Scrape NavLA for missing document names\n",
    "One of the issues I realized only later was that the initial table of documents provided by BOE for the volume count data was incomplete. There were more documents hosted on Navigate LA than revealed in that table. I wanted to fill out the difference. The first thing I did to get a more comprehensive listing of the documents on Navigate LA was run a small web crawler to loop through Traffic IDs (generated by BOE) and grab fileneames from each one.\n",
    "\n",
    "The script below scrapes the NavLA site, scraping the following pieces of information\n",
    "\n",
    "* intersection: The name of the intersection / location\n",
    "* node_id: The Bureau of Engineering CL_NODE_ID that corresponds to that location\n",
    "* automatic: A list of filenames for automatic count PDF documents \n",
    "* manual: A list of filenames for manual count PDF documents\n",
    "\n",
    "In addition, I will include the TrafficID, which I used for the query. The final result is a json dump, which will will then import later and use for joining to the BOE intersection and centerline file later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lxml import html, etree\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "\n",
    "Count_data = []\n",
    "\n",
    "# Base URL to use for the web scraping\n",
    "base_url = \"http://boemaps.eng.ci.la.ca.us/reports/dot_traffic_data_report.cfm?trafficid=\"\n",
    "\n",
    "# Loop through integers, grab all data in range\n",
    "for traffic_id in range(1,9000):\n",
    "    \n",
    "    # Metering the requests\n",
    "    time.sleep(.1)\n",
    "    \n",
    "    # The dictionary to hold the final data\n",
    "    d = {}\n",
    "    \n",
    "    # Make the request\n",
    "    url = base_url + str(traffic_id)\n",
    "    page = requests.get(url)\n",
    "    tree = html.fromstring(page.content)\n",
    "    \n",
    "    # Parse the data\n",
    "    table_info = tree.xpath('//td[@class=\"tablerecord\"]/text()')\n",
    "    if len(table_info) > 0:\n",
    "\n",
    "        # Parse the Node ID\n",
    "        node_id = tree.xpath('//td[@class=\"tablerecord\"]/text()')[0]\n",
    "        node_id = node_id.replace(u'\\xa0', u'')\n",
    "\n",
    "        # Parse the Intersection Name\n",
    "        intersection = tree.xpath('//td[@class=\"tablerecord\"]/text()')[1]\n",
    "        intersection = intersection.replace(u'\\r\\n\\t\\t\\t\\t\\r\\n\\t\\t\\t\\t\\t', u'')\n",
    "        intersection = intersection.replace(u'\\xa0\\r\\n\\t\\t\\t\\t\\r\\n\\t\\t\\t',u'')\n",
    "\n",
    "        ##### Automatic Counts\n",
    "        # Select the table that contains the automatic counts\n",
    "        automatic_count_table = tree.xpath('//b[text()=\"Automatic Count\"]/../../..')\n",
    "\n",
    "        # If there is at least automatic count PDF, grab filenames\n",
    "        if len(automatic_count_table) > 0:\n",
    "            automatic_count_table = etree.XML(etree.tostring(automatic_count_table[0]))\n",
    "            automatic_count_pdfs = automatic_count_table.xpath('//a/text()')\n",
    "            d['automatic'] = automatic_count_pdfs\n",
    "        else:\n",
    "            d['automatic'] = []\n",
    "\n",
    "        ##### Manual Counts\n",
    "        # Select the table that contains manual counts\n",
    "        manual_count_table = tree.xpath('//b[text()=\"Manual Count\"]/../../..')\n",
    "\n",
    "        # If there is at least manual count PDF, grab filenames\n",
    "        if len(manual_count_table) > 0:\n",
    "            manual_count_table = etree.XML(etree.tostring(manual_count_table[0]))\n",
    "            manual_count_pdfs = manual_count_table.xpath('//a/text()')\n",
    "            d['manual'] = manual_count_pdfs\n",
    "        else:\n",
    "            d['manual'] = []\n",
    "\n",
    "        d['node_id'] = node_id\n",
    "        d['traffic_id'] = traffic_id\n",
    "        d['intersection'] = intersection\n",
    "        Count_data.append(d)\n",
    "\n",
    "with open('data/TrafficCountFileStructure/navLAdump.txt', 'w') as outfile:\n",
    "    json.dump(Count_data, outfile)\n",
    "\n",
    "    # Verify\n",
    "print(Count_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [Update 1/7/18] Step 4: Complete the Library of Manual Count PDFs\n",
    "For this exercise, I wanted to collect the rest of the PDF files from the internet. I'll start by looking at the documents that I was able to pull from the web scrape exercise, join it with a table listing everything I have, and get the difference. From there, I can query NavigateLA by the PDF name and pull it down to my list of flies.\n",
    "\n",
    "Now that we have the data pulled from Navigate LA stored in navLAdump.txt, let's load it. I'll make some slight modificatons to the json data structure before we can bring it into a pandas data frame and join to the rest of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Lcoation of the json file\n",
    "traffic_count_file = 'data/TrafficCountFileStructure/navLAdump.txt'\n",
    "\n",
    "# Load json\n",
    "with open(traffic_count_file) as f:\n",
    "    traffic_count_files = json.load(f)\n",
    "\n",
    "# New list data structure\n",
    "count_files = []\n",
    "count_files_labels = ['cl_node_id','location','type','file']\n",
    "\n",
    "for location in traffic_count_files:\n",
    "    \n",
    "    # New list for each count, add intersection infomration & node id\n",
    "    count = []\n",
    "    node_id = location['node_id']\n",
    "    loc = location['intersection']\n",
    "    traffic_id = location['traffic_id']\n",
    "    \n",
    "    # Add a row for each manual count\n",
    "    if len(location['manual']) > 0:\n",
    "        for man in location['manual']:\n",
    "            man2 = man + '.PDF'\n",
    "            count = [node_id, loc, traffic_id, 'manual', man2]\n",
    "            count_files.append(count)\n",
    "    \n",
    "    # Add a row for each automatic count\n",
    "    if len(location['automatic']) > 0:\n",
    "        for auto in location['automatic']:\n",
    "            auto2 = auto + '.PDF'\n",
    "            count = [node_id, loc, traffic_id, 'automatic', auto2]\n",
    "            count_files.append(count)\n",
    "\n",
    "# Create the new dataframe\n",
    "count_files_df = pd.DataFrame.from_records(count_files, columns=count_files_labels)\n",
    "\n",
    "print(\"There are \" + str(len(count_files_df)) + \" files.\")\n",
    "count_files_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can then get that difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load traffic data files table\n",
    "traffic_data_files_path = 'data/TrafficCountFileStructure/boe_tables/dbo_dot_traffic_data_files.csv'\n",
    "dbo_dot_traffic_data_files = pd.read_csv(traffic_data_files_path,\n",
    "                                         parse_dates=['UploadDT'],\n",
    "                                         encoding=\"ISO-8859-1\")\n",
    "\n",
    "# Drop rows where TrafficID is NaN, convert TrafficID to int type\n",
    "dbo_dot_traffic_data_files = dbo_dot_traffic_data_files.dropna(axis=0, how='any', subset=['TrafficID'])\n",
    "dbo_dot_traffic_data_files['TrafficID'] = dbo_dot_traffic_data_files['TrafficID'].astype(int)\n",
    "\n",
    "# Subset out Survey Data and Automatic Counts\n",
    "dbo_dot_traffic_data_files = dbo_dot_traffic_data_files[(dbo_dot_traffic_data_files['TrafficType'] == 'manual_count')]\n",
    "\n",
    "# Uppercase the DocName in my table\n",
    "dbo_dot_traffic_data_files['DocName'] = dbo_dot_traffic_data_files['DocName'].str.upper()\n",
    "\n",
    "# Preview the table\n",
    "print(\"There are \" + str(len(dbo_dot_traffic_data_files)) + \" records in the table.\")\n",
    "dbo_dot_traffic_data_files.head()\n",
    "dbo_dot_traffic_data_files[(dbo_dot_traffic_data_files['DocName'] == 'DANIELS.PICO.170228-NDSMAN.PDF')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I want to join count_files_df to dbo_dot_traffic_data_files. The result will be that each count record will have an intersection that it can be assigned to from the BOE City of Los Angeles file. For the join, I'm going to use the PDF filename."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
